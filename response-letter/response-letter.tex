\documentclass{article}
\usepackage{todonotes}
\usepackage{a4wide}
\usepackage{xspace, comment}
\input{envirs}
\title{Response to the Reviewer's Comments}
\begin{document}

REFEREE REPORT 1\\

We thank the reviewer for taking the time to review our manuscript. We have carefully considered the reviewer's meaningful comments and accordingly revised our manuscript. We hope that our revision improves the paper to the level of the reviewer's satisfaction. In the following, we firstly quote the reviewer's comment (as RC) and then provide our response with the corresponding changes highlighted in blue in the revised manuscript.


\begin{verbatim}
> R1C1
> Microservices can also be deployed in micro-VMs like AWS’s Firecracker, which are latency sensitive.
\end{verbatim}

In response to this comment, we mention microVMs in Introduction as follows.

Since these containers are typically deployed on VMs \kw{(including microVMs such as Firecracker of Amazon AWS)} rather than bare-metal servers~\cite{cai2023automan,wang2024autothrottle,entrialgo2024joint,bermejo2024goodness}, it is essential for VMs to be allocated sufficient CPU resources and network bandwidth to meet the network latency requirements.
\\

\begin{verbatim}
> R1C2
> To the reviewer’s knowledge, vCPU prioritization may not lead to more CPU time allocation. vCPU prioritization means the vCPU has higher priority. For example, a vCPU thread (a vCPU in the guest is actually a thread in the host) consumes less CPU time (e.g., responsible for I/O) will be prioritized by the Linux CFS; this does not mean this vCPU will obtain more CPU time.
\end{verbatim}

In response to this comment, \\


\begin{verbatim}
> R1C3
>  It’s unclear to me what the challenges of the proposed solution are. I think the paper can become better if the challenges and their corresponding solutions are described in the introduction.
\end{verbatim}

In response to this comment, we add challenges and corresponding solutions in Introduction as follows.
\kw{These limitations highlight three challenges in meeting network bandwidth SLOs for VMs. First, the CPU needed to sustain a target bandwidth is highly workload-, message-size-, and hardware-dependent, so a fixed Mbps→CPU rule can easily over- or under-provision. Second, bandwidth delivery depends on a coupled host–guest packet-processing pipeline (guest stack/virtio and host vhost/qemu/kernel), where the bottleneck can shift with contention, making naïve provisioning unstable. Third, real services are often multi-threaded and run in multi-vCPU VMs, introducing scaling and scheduling effects that complicate both accurate modeling and robust CPU enforcement for bandwidth requirements.}

\kw{This paper presents the design and implementation of \name, a general framework for translating network bandwidth SLOs into CPU allocations for VMs. \name tackles the three challenges above as follows. First, to handle the strong dependence of CPU demand on workload behavior, message size, and hardware, \name performs lightweight per-setting profiling: for each target workload specification (including message size and platform), it collects training samples by sweeping CPU allocations and measuring the resulting bandwidth, requiring up to 16 minutes in total for data collection and model building. Second, to account for the coupled host–guest packet-processing pipeline, \name explicitly separates their effects by learning two regression models, one for guest-side CPU usage and one for host-side CPU usage, and composes their predictions to estimate the CPU needed to sustain the target bandwidth. Third, to remain robust to multi-threaded services and varying numbers of vCPU, \name enforces allocations only at the host level (rather than controlling in-guest CPU usage). This enables \name to be independent of the guest’s internal threading model and vCPU configuration while still ensuring bandwidth requirements.}
\\


\begin{verbatim}
> R1C4
>  It’s unclear to me why the network scheduling approaches do not work. It’s better to explain “why this approach is effective only when…”.
\end{verbatim}

We revised the original manuscript why existing techniques do not work in Introduction as follows.

\kw{Prior work has primarily pursued two directions—network scheduling and vCPU prioritization—to meet the bandwidth requirements. However, neither approach fully addresses meeting network bandwidth requirements in VMs. First, network scheduling~\cite{jang2015silo,jeyakumar2013eyeq,russell2008virtio} controls per-VM transmission rates via queueing and shaping, yet it implicitly assumes that the VM will receive \textbf{enough CPU time} to process packets at the desired rate; when CPU becomes the bottleneck (e.g., high packet-per-second traffic or CPU contention), the CPU scheduler—being oblivious to bandwidth requirements—can cap packet processing and prevent the target bandwidth from being reached even if rate limits are configured. 
Second, vCPU prioritization (including weight-based CPU sharing)~\cite{jia2018effectively,jia2020vsmt,xu2013vturbo,suo2017preserving} attempts to favor VMs with bandwidth requirements, but it does not directly answer the central question of \textit{how much CPU is needed for a given bandwidth target}. Without an accurate mapping, VMs have difficulty in meeting the bandwidth requirements accurately and efficiently.}


REFEREE REPORT 2\\

We would like to thank the reviewer for the careful and thorough reading of this manuscript. We have revised our present manuscript based on your meaningful comments and suggestions, and hope that our revision has improved the paper to the level of the reviewer's satisfaction. In the following, we firstly quote the reviewer's comment (as RC) and then provide our response with the corresponding changes highlighted in red in the revised manuscript.

\begin{verbatim}

> R2C1
> The comparison against state-of-the-art ML resource management techniques (FIRM, Sinan, Autothrottle) is currently limited to a high-level comparison table focusing on input/output parameters and time overheads. Since the authors note difficulties in direct performance comparison due to differences in focus (VM-level vs. container/microservice, resource features), the discussion should be expanded to more deeply rationalize why TASADOR's simpler model (RFR) performs better for this specific problem instance (network bandwidth to CPU translation), even compared to the developed Multi-Layer Perceptron (MLP) model, which was 1.3× to 1.4× less accurate.
\end{verbatim}

In response to this comment, we have added a discussion why simple RFR performs better for the problem in Discussion as follows.

\paragraphb{Why a simple Random Forest model is effective for bandwidth-to-CPU translation}
\kw{Although prior ML-based resource managers learn policies over multiple resources and objectives (e.g., latency under multi-dimensional contention), the bandwidth-to-CPU translation targeted by \name exhibits a structured relationship that is well-suited to lightweight regression.
For a fixed workload and traffic specification, achieved bandwidth typically increases with CPU budget but \emph{saturates} near the maximum capacity due to bottlenecks in the end-host packet-processing pipeline (e.g., softirq/vhost/virtio and application processing).
This produces a monotone yet non-linear curve with a near-linear region at low CPU budgets and diminishing returns as the system approaches its throughput ceiling.
Random Forest Regression (RFR) matches this structure: as an ensemble of decision trees, it captures saturation and interaction effects (e.g., message size/packet rate and hardware configuration) without extensive feature engineering, while remaining fast to train from modest datasets.}
\\

\begin{verbatim}
> R2C2
> The discussion on handling diverse network traffic patterns notes that TASADOR selects worst-case parameters (e.g., smallest message size or most bursty pattern) which *often results in over-provisioning of CPU* under non-peak load conditions. While resource redistribution mitigates waste, it would strengthen the evaluation to explicitly quantify the degree of CPU over-provisioning (e.g., predicted CPU vs. actually needed CPU) during off-peak times in the dynamic load scenario to fully characterize the trade-off.
\end{verbatim}

We appreciate the comment and acknowledge that there is no explanation on the impact of over-provisionning. To quantify the impact of \name on over-provisioning, we calculate wastes in CPU utilization that are minus actual usage from the predicted allocation depending on the traffic load in Table~\ref{table:overprov}. Our evaluation results show that the maximum CPU waste is 56.1\% with the 0\% of traffic load. However, the unused CPU is yielded to other VMs (VM2 in our experiment), increasing the CPU utilization by 121.3\% on average. \\

\begin{verbatim}
> R2C3
> In the noisy neighbors evaluation, TASADOR achieves 0% SLO violation rate. The authors should briefly elaborate on how TASADOR's allocation mechanism successfully isolates the target VM from these high-contention resource aggressors to maintain 0% SLO violations, especially since the competing network scheduling scheme (tc) experienced a 20% SLO violation rate against CPU-bound neighbors.
In addition, please consider adding contention in memory bandwidth dimension as well.

\end{verbatim}

In response to this comment, we have added an explanation of why \name isolates the target VM from noisy neighbors in Appendix as follows. 
\kw{In contrast, \texttt{tc} suffers a $20$\% violation rate under CPU contention. Because \texttt{tc} lacks a mechanism to guarantee the CPU cycles required to process packets at the specified rate, the target VM's network processing is frequently preempted or delayed by the CPU-bound stressor. While vCPU prioritization reduces these violations, it lacks the precision of \name's translation model, leading to significant over-provisioning and high bandwidth variation (up to $72.9$). For instance, under network-bound noise, prioritization results in a $39$\% higher bandwidth than requested ($277$ Mbps).}

\kw{Ultimately, \name's advantage lies in its ability to treat network SLOs as a multi-resource allocation problem. By shielding the network-related CPU demand from host-level contention, \name maintains stable performance where traditional packet-level scheduling (\texttt{tc}) or coarse-grained prioritization fails.}
\\

\begin{verbatim}
> R2C4
> In terms of adaption to new workload, 16 minutes might still be an overhead for dynamic online workloads. Please consider how a learned model can generalize to changing workload or changing environment, like this paper FLASH.

\end{verbatim}


\begin{verbatim}
> R2C5
> The authors should elaborate on how mispredictions are handled.Overprediction leads to overprovisioning, though it's conservative linux scheduler, still for cloud providers, it's hard to resell the CPU cores to other customers through oversubscription; underprediction is even worse.

\end{verbatim}

We thank the reviewer for this insightful observation. We agree that mispredictions—both overprediction (leading to inefficient resource utilization) and underprediction (resulting in SLO violations)—are critical factors for cloud providers.
In its current form, \name addresses this by significantly increasing the precision of the initial "bandwidth-to-CPU" mapping through its ML-based translation, which reduces the margin of error compared to traditional static or coarse-grained allocation methods. However, we acknowledge that a static prediction may not account for unexpected runtime fluctuations or model drift.
To address this, we envision extending \name with a dynamic monitoring and feedback loop as part of our future work. This mechanism will involve:
Continuous Monitoring: Real-time tracking of actual network bandwidth and CPU consumption.
Drift Detection: Comparing actual performance against the ML model's predicted targets.
Periodic Re-adjustment: If a deviation (misprediction) exceeds a predefined threshold, the system will trigger a localized re-allocation of CPU shares to either reclaim wasted resources (in the case of overprediction) or restore SLO compliance (in the case of underprediction).
We have updated the Conclusion section to highlight this extension as a key direction for future research.


REFEREE REPORT 3\\

We would like to thank the reviewer for the careful and thorough reading of this manuscript. We hope that our revision has improved the paper to the level of the reviewer's satisfaction. In the following, we firstly quote the reviewer's comment (as RC) and then provide our response with the corresponding changes highlighted in red in the revised manuscript.

\begin{verbatim}
> R3C1
> It is not clear how the proposed approach differs from existing methods discussed in the related work section. Please clearly explain what is new and what improvements are achieved compared to previous work.
\end{verbatim}

In response to this comment, we revised Related work to clarify the differences between the existing methods and our work. In particular, at the beginning of the section, we elaborate the summarized version of existing methods and the difference as follows.
\kw{Prior work either (i) shapes network egress without translating bandwidth intent into CPU budgets,
(ii) biases scheduling toward I/O-oriented vCPUs without computing the CPU needed for a specific bandwidth target,
(iii) reallocates whole cores or iteratively tunes quotas for latency objectives, or
(iv) applies ML for multi-resource SLO control mainly in native/container settings.
In contrast, \name targets \emph{VM-level bandwidth requirements} and introduces a lightweight, host--guest-aware model that directly predicts the host CPU quota needed to sustain a given bandwidth target.}
\\

\begin{verbatim}
> R3C2
> The system architecture is explained at a high level, which is useful. It is mentioned that “our model training is notably fast compared to other ML training schemes, which often require several hours to attain reasonable accuracy.” However, the training process appears simpler because the training data are collected from a VM with simulated workloads. It would be interesting to discuss whether such simply trained ML models can accurately predict workloads of real-world, complex use cases and enforce CPU allocation with finer granularity. Please clarify this point.
\end{verbatim}

We appreciate the comment
\\

\begin{verbatim}
> R3C3
> Some assumptions and design choices are made in the system design, but the reasons for these choices are not always explained. For example, three supervised ML models (LR, SVR, and RFR) are used for regression. Providing simple justifications for selecting these models would strengthen the paper. This reviewer also notes that adaptive learning approaches, such as reinforcement learning, may offer better performance and could be discussed.

\end{verbatim}

We appreciate the reviewer’s suggestion to clarify our model selection. We evaluate LR, SVR, and RFR because the bandwidth–CPU relationship in virtualized endpoints is typically monotone with a near-linear region at low CPU budgets and a saturation region near peak throughput, and we require models that (i) train quickly under a tight profiling budget and (ii) remain robust under measurement noise. LR provides a simple baseline for the near-linear regime; SVR improves robustness to noise/outliers commonly observed in shared clouds; and RFR captures non-linearities (e.g., saturation) and feature interactions (e.g., message size and hardware effects) while remaining computationally lightweight. We also evaluate an MLP in our model study and find that, under the same profiling budget, it is less accurate than RFR, consistent with the fact that deep models often require larger datasets and careful tuning to generalize reliably.
Regarding reinforcement learning (RL) and other adaptive approaches, we agree that RL can be effective for closed-loop control in highly dynamic and partially observed environments. However, for the specific task of bandwidth-to-CPU translation, RL typically relies on online exploration or iterative adjustment to learn a policy, which can introduce transient under-provisioning or oscillations during adaptation—undesirable when bandwidth requirements must be met consistently. In the revised manuscript (Section [X]), we therefore position RL as a promising future direction (e.g., hybrid designs with safe adaptation), while motivating our current choice of supervised regression as a stable, low-overhead solution that delivers accurate one-shot CPU predictions.

\\

\begin{verbatim}
> R3C4
> It is not clear how the traffic used in the evaluation resembles real-world use cases or application traffic. For the evaluation of web server bandwidth requirement fulfillment, it is unclear how many clients are considered and what traffic models and characteristics (e.g., packet sizes, session arrival models, session durations, response time requirements) are assumed. Please clarify these aspects.
\end{verbatim}

We thank the reviewer for requesting clarification of our traffic model. Our evaluation uses a standard closed-loop concurrency workload (constant number of concurrent clients issuing requests as soon as the previous request completes), which stresses the end-host packet-processing path under peak load. For Apache, we maintain 1,000 concurrent TCP connections repeatedly fetching a 1 KB static object in the fixed-load scenario, and in the dynamic-load scenario, we vary concurrency from 512 → 4 → 2 to emulate demand fluctuations. For Memcached, we use 1,000 concurrent clients issuing 100,000 operations per trial with a read-heavy GET/SET mix (9:1) (and we now explicitly report key parameters such as request sizes and concurrency). We have updated Section [X] to state the client counts, object/request sizes, and the closed-loop session model used in each experiment.
\\


\end{document}
